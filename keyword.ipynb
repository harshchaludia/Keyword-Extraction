{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Keyword Extraction using NLTK Library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input text is given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "finaltext = open(\"F:/python progs/RAKE-tutorial-master/RAKE-tutorial-master/extract.txt\", \"r\",encoding=\"utf-8\")\n",
    "Text = finaltext.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw input text is cleaned off non-printable characters (if any) and turned into lower case.\n",
    "The processed input text is then tokenized using NLTK library functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Text: \n",
      "\n",
      "['Lorem', 'Ipsum', 'is', 'simply', 'dummy', 'text', 'of', 'the', 'printing', 'and', 'typesetting', 'industry', '.', 'Lorem', 'Ipsum', 'has', 'been', 'the', 'industry', \"'s\", 'standard', 'dummy', 'text', 'ever', 'since', 'the', '1500s', ',', 'when', 'an', 'unknown', 'printer', 'took', 'a', 'galley', 'of', 'type', 'and', 'scrambled', 'it', 'to', 'make', 'a', 'type', 'specimen', 'book', '.', 'It', 'has', 'survived', 'not', 'only', 'five', 'centuries', ',', 'but', 'also', 'the', 'leap', 'into', 'electronic', 'typesetting', ',', 'remaining', 'essentially', 'unchanged', '.', 'It', 'was', 'popularised', 'in', 'the', '1960s', 'with', 'the', 'release', 'of', 'Letraset', 'sheets', 'containing', 'Lorem', 'Ipsum', 'passages', ',', 'and', 'more', 'recently', 'with', 'desktop', 'publishing', 'software', 'like', 'Aldus', 'PageMaker', 'including', 'versions', 'of', 'Lorem', 'Ipsum', '.', 'It', 'is', 'a', 'long', 'established', 'fact', 'that', 'a', 'reader', 'will', 'be', 'distracted', 'by', 'the', 'readable', 'content', 'of', 'a', 'page', 'when', 'looking', 'at', 'its', 'layout', '.', 'The', 'point', 'of', 'using', 'Lorem', 'Ipsum', 'is', 'that', 'it', 'has', 'a', 'more-or-less', 'normal', 'distribution', 'of', 'letters', ',', 'as', 'opposed', 'to', 'using', \"'Content\", 'here', ',', 'content', 'here', \"'\", ',', 'making', 'it', 'look', 'like', 'readable', 'English', '.', 'Many', 'desktop', 'publishing', 'packages', 'and', 'web', 'page', 'editors', 'now', 'use', 'Lorem', 'Ipsum', 'as', 'their', 'default', 'model', 'text', ',', 'and', 'a', 'search', 'for', \"'lorem\", 'ipsum', \"'\", 'will', 'uncover', 'many', 'web', 'sites', 'still', 'in', 'their', 'infancy', '.', 'Various', 'versions', 'have', 'evolved', 'over', 'the', 'years', ',', 'sometimes', 'by', 'accident', ',', 'sometimes', 'on', 'purpose', '(', 'injected', 'humour', 'and', 'the', 'like', ')', '.There', 'are', 'many', 'variations', 'of', 'passages', 'of', 'Lorem', 'Ipsum', 'available', ',', 'but', 'the', 'majority', 'have', 'suffered', 'alteration', 'in', 'some', 'form', ',', 'by', 'injected', 'humour', ',', 'or', 'randomised', 'words', 'which', 'do', \"n't\", 'look', 'even', 'slightly', 'believable', '.', 'If', 'you', 'are', 'going', 'to', 'use', 'a', 'passage', 'of', 'Lorem', 'Ipsum', ',', 'you', 'need', 'to', 'be', 'sure', 'there', 'is', \"n't\", 'anything', 'embarrassing', 'hidden', 'in', 'the', 'middle', 'of', 'text', '.', 'All', 'the', 'Lorem', 'Ipsum', 'generators', 'on', 'the', 'Internet', 'tend', 'to', 'repeat', 'predefined', 'chunks', 'as', 'necessary', ',', 'making', 'this', 'the', 'first', 'true', 'generator', 'on', 'the', 'Internet', '.', 'It', 'uses', 'a', 'dictionary', 'of', 'over', '200', 'Latin', 'words', ',', 'combined', 'with', 'a', 'handful', 'of', 'model', 'sentence', 'structures', ',', 'to', 'generate', 'Lorem', 'Ipsum', 'which', 'looks', 'reasonable', '.', 'The', 'generated', 'Lorem', 'Ipsum', 'is', 'therefore', 'always', 'free', 'from', 'repetition', ',', 'injected', 'humour', ',', 'or', 'non-characteristic', 'words', 'etc', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "text = word_tokenize(Text)\n",
    "\n",
    "print(\"Tokenized Text: \\n\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK is again used for <b>POS tagging</b> the input text.\n",
    "\n",
    "\n",
    "Description of POS tags: \n",
    "http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Text with POS tags: \n",
      "\n",
      "[('Lorem', 'NNP'), ('Ipsum', 'NNP'), ('is', 'VBZ'), ('simply', 'RB'), ('dummy', 'JJ'), ('text', 'NN'), ('of', 'IN'), ('the', 'DT'), ('printing', 'NN'), ('and', 'CC'), ('typesetting', 'NN'), ('industry', 'NN'), ('.', '.'), ('Lorem', 'NNP'), ('Ipsum', 'NNP'), ('has', 'VBZ'), ('been', 'VBN'), ('the', 'DT'), ('industry', 'NN'), (\"'s\", 'POS'), ('standard', 'JJ'), ('dummy', 'NN'), ('text', 'NN'), ('ever', 'RB'), ('since', 'IN'), ('the', 'DT'), ('1500s', 'CD'), (',', ','), ('when', 'WRB'), ('an', 'DT'), ('unknown', 'JJ'), ('printer', 'NN'), ('took', 'VBD'), ('a', 'DT'), ('galley', 'NN'), ('of', 'IN'), ('type', 'NN'), ('and', 'CC'), ('scrambled', 'VBD'), ('it', 'PRP'), ('to', 'TO'), ('make', 'VB'), ('a', 'DT'), ('type', 'NN'), ('specimen', 'NNS'), ('book', 'NN'), ('.', '.'), ('It', 'PRP'), ('has', 'VBZ'), ('survived', 'VBN'), ('not', 'RB'), ('only', 'RB'), ('five', 'CD'), ('centuries', 'NNS'), (',', ','), ('but', 'CC'), ('also', 'RB'), ('the', 'DT'), ('leap', 'NN'), ('into', 'IN'), ('electronic', 'JJ'), ('typesetting', 'NN'), (',', ','), ('remaining', 'VBG'), ('essentially', 'RB'), ('unchanged', 'JJ'), ('.', '.'), ('It', 'PRP'), ('was', 'VBD'), ('popularised', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('1960s', 'NNS'), ('with', 'IN'), ('the', 'DT'), ('release', 'NN'), ('of', 'IN'), ('Letraset', 'NNP'), ('sheets', 'NNS'), ('containing', 'VBG'), ('Lorem', 'NNP'), ('Ipsum', 'NNP'), ('passages', 'NNS'), (',', ','), ('and', 'CC'), ('more', 'RBR'), ('recently', 'RB'), ('with', 'IN'), ('desktop', 'NN'), ('publishing', 'NN'), ('software', 'NN'), ('like', 'IN'), ('Aldus', 'NNP'), ('PageMaker', 'NNP'), ('including', 'VBG'), ('versions', 'NNS'), ('of', 'IN'), ('Lorem', 'NNP'), ('Ipsum', 'NNP'), ('.', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('long', 'JJ'), ('established', 'VBN'), ('fact', 'NN'), ('that', 'IN'), ('a', 'DT'), ('reader', 'NN'), ('will', 'MD'), ('be', 'VB'), ('distracted', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('readable', 'JJ'), ('content', 'NN'), ('of', 'IN'), ('a', 'DT'), ('page', 'NN'), ('when', 'WRB'), ('looking', 'VBG'), ('at', 'IN'), ('its', 'PRP$'), ('layout', 'NN'), ('.', '.'), ('The', 'DT'), ('point', 'NN'), ('of', 'IN'), ('using', 'VBG'), ('Lorem', 'NNP'), ('Ipsum', 'NNP'), ('is', 'VBZ'), ('that', 'IN'), ('it', 'PRP'), ('has', 'VBZ'), ('a', 'DT'), ('more-or-less', 'JJ'), ('normal', 'JJ'), ('distribution', 'NN'), ('of', 'IN'), ('letters', 'NNS'), (',', ','), ('as', 'IN'), ('opposed', 'VBN'), ('to', 'TO'), ('using', 'VBG'), (\"'Content\", 'NN'), ('here', 'RB'), (',', ','), ('content', 'NN'), ('here', 'RB'), (\"'\", \"''\"), (',', ','), ('making', 'VBG'), ('it', 'PRP'), ('look', 'VB'), ('like', 'IN'), ('readable', 'JJ'), ('English', 'NNP'), ('.', '.'), ('Many', 'JJ'), ('desktop', 'NN'), ('publishing', 'NN'), ('packages', 'NNS'), ('and', 'CC'), ('web', 'JJ'), ('page', 'NN'), ('editors', 'NNS'), ('now', 'RB'), ('use', 'VBP'), ('Lorem', 'NNP'), ('Ipsum', 'NNP'), ('as', 'IN'), ('their', 'PRP$'), ('default', 'NN'), ('model', 'NN'), ('text', 'NN'), (',', ','), ('and', 'CC'), ('a', 'DT'), ('search', 'NN'), ('for', 'IN'), (\"'lorem\", 'NNP'), ('ipsum', 'NN'), (\"'\", \"''\"), ('will', 'MD'), ('uncover', 'VB'), ('many', 'JJ'), ('web', 'NN'), ('sites', 'NNS'), ('still', 'RB'), ('in', 'IN'), ('their', 'PRP$'), ('infancy', 'NN'), ('.', '.'), ('Various', 'JJ'), ('versions', 'NNS'), ('have', 'VBP'), ('evolved', 'VBN'), ('over', 'IN'), ('the', 'DT'), ('years', 'NNS'), (',', ','), ('sometimes', 'RB'), ('by', 'IN'), ('accident', 'NN'), (',', ','), ('sometimes', 'RB'), ('on', 'IN'), ('purpose', 'NN'), ('(', '('), ('injected', 'VBN'), ('humour', 'NN'), ('and', 'CC'), ('the', 'DT'), ('like', 'JJ'), (')', ')'), ('.There', 'EX'), ('are', 'VBP'), ('many', 'JJ'), ('variations', 'NNS'), ('of', 'IN'), ('passages', 'NNS'), ('of', 'IN'), ('Lorem', 'NNP'), ('Ipsum', 'NNP'), ('available', 'JJ'), (',', ','), ('but', 'CC'), ('the', 'DT'), ('majority', 'NN'), ('have', 'VBP'), ('suffered', 'VBN'), ('alteration', 'NN'), ('in', 'IN'), ('some', 'DT'), ('form', 'NN'), (',', ','), ('by', 'IN'), ('injected', 'JJ'), ('humour', 'NN'), (',', ','), ('or', 'CC'), ('randomised', 'VBD'), ('words', 'NNS'), ('which', 'WDT'), ('do', 'VBP'), (\"n't\", 'RB'), ('look', 'VB'), ('even', 'RB'), ('slightly', 'RB'), ('believable', 'JJ'), ('.', '.'), ('If', 'IN'), ('you', 'PRP'), ('are', 'VBP'), ('going', 'VBG'), ('to', 'TO'), ('use', 'VB'), ('a', 'DT'), ('passage', 'NN'), ('of', 'IN'), ('Lorem', 'NNP'), ('Ipsum', 'NNP'), (',', ','), ('you', 'PRP'), ('need', 'VBP'), ('to', 'TO'), ('be', 'VB'), ('sure', 'JJ'), ('there', 'EX'), ('is', 'VBZ'), (\"n't\", 'RB'), ('anything', 'NN'), ('embarrassing', 'JJ'), ('hidden', 'NN'), ('in', 'IN'), ('the', 'DT'), ('middle', 'NN'), ('of', 'IN'), ('text', 'NN'), ('.', '.'), ('All', 'PDT'), ('the', 'DT'), ('Lorem', 'NNP'), ('Ipsum', 'NNP'), ('generators', 'NNS'), ('on', 'IN'), ('the', 'DT'), ('Internet', 'NNP'), ('tend', 'NN'), ('to', 'TO'), ('repeat', 'VB'), ('predefined', 'JJ'), ('chunks', 'NNS'), ('as', 'IN'), ('necessary', 'JJ'), (',', ','), ('making', 'VBG'), ('this', 'DT'), ('the', 'DT'), ('first', 'JJ'), ('true', 'JJ'), ('generator', 'NN'), ('on', 'IN'), ('the', 'DT'), ('Internet', 'NNP'), ('.', '.'), ('It', 'PRP'), ('uses', 'VBZ'), ('a', 'DT'), ('dictionary', 'NN'), ('of', 'IN'), ('over', 'IN'), ('200', 'CD'), ('Latin', 'JJ'), ('words', 'NNS'), (',', ','), ('combined', 'VBN'), ('with', 'IN'), ('a', 'DT'), ('handful', 'NN'), ('of', 'IN'), ('model', 'NN'), ('sentence', 'NN'), ('structures', 'NNS'), (',', ','), ('to', 'TO'), ('generate', 'VB'), ('Lorem', 'NNP'), ('Ipsum', 'NNP'), ('which', 'WDT'), ('looks', 'VBZ'), ('reasonable', 'JJ'), ('.', '.'), ('The', 'DT'), ('generated', 'JJ'), ('Lorem', 'NNP'), ('Ipsum', 'NNP'), ('is', 'VBZ'), ('therefore', 'RB'), ('always', 'RB'), ('free', 'JJ'), ('from', 'IN'), ('repetition', 'NN'), (',', ','), ('injected', 'VBD'), ('humour', 'NN'), (',', ','), ('or', 'CC'), ('non-characteristic', 'JJ'), ('words', 'NNS'), ('etc', 'FW'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#nltk.download('averaged_perceptron_tagger')\n",
    "  \n",
    "POS_tag = nltk.pos_tag(text)\n",
    "print(\"Tokenized Text with POS tags: \\n\")\n",
    "print(POS_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenized text (mainly the nouns and adjectives) is normalized by <b>lemmatization</b>.\n",
    "In lemmatization different grammatical counterparts of a word will be replaced by single\n",
    "basic lemma. For example, 'glasses' may be replaced by 'glass'. \n",
    "\n",
    "Details about lemmatization: \n",
    "    \n",
    "https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text tokens after lemmatization of adjectives and nouns: \n",
      "\n",
      "['Lorem', 'Ipsum', 'is', 'simply', 'dummy', 'text', 'of', 'the', 'printing', 'and', 'typesetting', 'industry', '.', 'Lorem', 'Ipsum', 'ha', 'been', 'the', 'industry', \"'s\", 'standard', 'dummy', 'text', 'ever', 'since', 'the', '1500s', ',', 'when', 'an', 'unknown', 'printer', 'took', 'a', 'galley', 'of', 'type', 'and', 'scrambled', 'it', 'to', 'make', 'a', 'type', 'specimen', 'book', '.', 'It', 'ha', 'survived', 'not', 'only', 'five', 'century', ',', 'but', 'also', 'the', 'leap', 'into', 'electronic', 'typesetting', ',', 'remaining', 'essentially', 'unchanged', '.', 'It', 'wa', 'popularised', 'in', 'the', '1960s', 'with', 'the', 'release', 'of', 'Letraset', 'sheet', 'containing', 'Lorem', 'Ipsum', 'passage', ',', 'and', 'more', 'recently', 'with', 'desktop', 'publishing', 'software', 'like', 'Aldus', 'PageMaker', 'including', 'version', 'of', 'Lorem', 'Ipsum', '.', 'It', 'is', 'a', 'long', 'established', 'fact', 'that', 'a', 'reader', 'will', 'be', 'distracted', 'by', 'the', 'readable', 'content', 'of', 'a', 'page', 'when', 'looking', 'at', 'it', 'layout', '.', 'The', 'point', 'of', 'using', 'Lorem', 'Ipsum', 'is', 'that', 'it', 'ha', 'a', 'more-or-less', 'normal', 'distribution', 'of', 'letter', ',', 'a', 'opposed', 'to', 'using', \"'Content\", 'here', ',', 'content', 'here', \"'\", ',', 'making', 'it', 'look', 'like', 'readable', 'English', '.', 'Many', 'desktop', 'publishing', 'package', 'and', 'web', 'page', 'editor', 'now', 'use', 'Lorem', 'Ipsum', 'a', 'their', 'default', 'model', 'text', ',', 'and', 'a', 'search', 'for', \"'lorem\", 'ipsum', \"'\", 'will', 'uncover', 'many', 'web', 'site', 'still', 'in', 'their', 'infancy', '.', 'Various', 'version', 'have', 'evolved', 'over', 'the', 'year', ',', 'sometimes', 'by', 'accident', ',', 'sometimes', 'on', 'purpose', '(', 'injected', 'humour', 'and', 'the', 'like', ')', '.There', 'are', 'many', 'variation', 'of', 'passage', 'of', 'Lorem', 'Ipsum', 'available', ',', 'but', 'the', 'majority', 'have', 'suffered', 'alteration', 'in', 'some', 'form', ',', 'by', 'injected', 'humour', ',', 'or', 'randomised', 'word', 'which', 'do', \"n't\", 'look', 'even', 'slightly', 'believable', '.', 'If', 'you', 'are', 'going', 'to', 'use', 'a', 'passage', 'of', 'Lorem', 'Ipsum', ',', 'you', 'need', 'to', 'be', 'sure', 'there', 'is', \"n't\", 'anything', 'embarrassing', 'hidden', 'in', 'the', 'middle', 'of', 'text', '.', 'All', 'the', 'Lorem', 'Ipsum', 'generator', 'on', 'the', 'Internet', 'tend', 'to', 'repeat', 'predefined', 'chunk', 'a', 'necessary', ',', 'making', 'this', 'the', 'first', 'true', 'generator', 'on', 'the', 'Internet', '.', 'It', 'us', 'a', 'dictionary', 'of', 'over', '200', 'Latin', 'word', ',', 'combined', 'with', 'a', 'handful', 'of', 'model', 'sentence', 'structure', ',', 'to', 'generate', 'Lorem', 'Ipsum', 'which', 'look', 'reasonable', '.', 'The', 'generated', 'Lorem', 'Ipsum', 'is', 'therefore', 'always', 'free', 'from', 'repetition', ',', 'injected', 'humour', ',', 'or', 'non-characteristic', 'word', 'etc', '.']\n"
     ]
    }
   ],
   "source": [
    "#nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "adjective_tags = ['JJ','JJR','JJS']\n",
    "\n",
    "lemmatized_text = []\n",
    "\n",
    "for word in POS_tag:\n",
    "    if word[1] in adjective_tags:\n",
    "        lemmatized_text.append(str(wordnet_lemmatizer.lemmatize(word[0],pos=\"a\")))\n",
    "    else:\n",
    "        lemmatized_text.append(str(wordnet_lemmatizer.lemmatize(word[0]))) #default POS = noun\n",
    "        \n",
    "print(\"Text tokens after lemmatization of adjectives and nouns: \\n\")\n",
    "print(lemmatized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>lemmatized text</b> is <b>POS tagged</b> here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized text with POS tags: \n",
      "\n",
      "[('Lorem', 'NNP'), ('Ipsum', 'NNP'), ('is', 'VBZ'), ('simply', 'RB'), ('dummy', 'JJ'), ('text', 'NN'), ('of', 'IN'), ('the', 'DT'), ('printing', 'NN'), ('and', 'CC'), ('typesetting', 'NN'), ('industry', 'NN'), ('.', '.'), ('Lorem', 'NNP'), ('Ipsum', 'NNP'), ('ha', 'VBD'), ('been', 'VBN'), ('the', 'DT'), ('industry', 'NN'), (\"'s\", 'POS'), ('standard', 'JJ'), ('dummy', 'NN'), ('text', 'NN'), ('ever', 'RB'), ('since', 'IN'), ('the', 'DT'), ('1500s', 'CD'), (',', ','), ('when', 'WRB'), ('an', 'DT'), ('unknown', 'JJ'), ('printer', 'NN'), ('took', 'VBD'), ('a', 'DT'), ('galley', 'NN'), ('of', 'IN'), ('type', 'NN'), ('and', 'CC'), ('scrambled', 'VBD'), ('it', 'PRP'), ('to', 'TO'), ('make', 'VB'), ('a', 'DT'), ('type', 'NN'), ('specimen', 'NNS'), ('book', 'NN'), ('.', '.'), ('It', 'PRP'), ('ha', 'VBZ'), ('survived', 'VBD'), ('not', 'RB'), ('only', 'RB'), ('five', 'CD'), ('century', 'NN'), (',', ','), ('but', 'CC'), ('also', 'RB'), ('the', 'DT'), ('leap', 'NN'), ('into', 'IN'), ('electronic', 'JJ'), ('typesetting', 'NN'), (',', ','), ('remaining', 'VBG'), ('essentially', 'RB'), ('unchanged', 'JJ'), ('.', '.'), ('It', 'PRP'), ('wa', 'VBD'), ('popularised', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('1960s', 'NNS'), ('with', 'IN'), ('the', 'DT'), ('release', 'NN'), ('of', 'IN'), ('Letraset', 'NNP'), ('sheet', 'NN'), ('containing', 'VBG'), ('Lorem', 'NNP'), ('Ipsum', 'NNP'), ('passage', 'NN'), (',', ','), ('and', 'CC'), ('more', 'RBR'), ('recently', 'RB'), ('with', 'IN'), ('desktop', 'NN'), ('publishing', 'NN'), ('software', 'NN'), ('like', 'IN'), ('Aldus', 'NNP'), ('PageMaker', 'NNP'), ('including', 'VBG'), ('version', 'NN'), ('of', 'IN'), ('Lorem', 'NNP'), ('Ipsum', 'NNP'), ('.', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('long', 'JJ'), ('established', 'VBN'), ('fact', 'NN'), ('that', 'IN'), ('a', 'DT'), ('reader', 'NN'), ('will', 'MD'), ('be', 'VB'), ('distracted', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('readable', 'JJ'), ('content', 'NN'), ('of', 'IN'), ('a', 'DT'), ('page', 'NN'), ('when', 'WRB'), ('looking', 'VBG'), ('at', 'IN'), ('it', 'PRP'), ('layout', 'RB'), ('.', '.'), ('The', 'DT'), ('point', 'NN'), ('of', 'IN'), ('using', 'VBG'), ('Lorem', 'NNP'), ('Ipsum', 'NNP'), ('is', 'VBZ'), ('that', 'IN'), ('it', 'PRP'), ('ha', 'VBZ'), ('a', 'DT'), ('more-or-less', 'JJ'), ('normal', 'JJ'), ('distribution', 'NN'), ('of', 'IN'), ('letter', 'NN'), (',', ','), ('a', 'DT'), ('opposed', 'VBN'), ('to', 'TO'), ('using', 'VBG'), (\"'Content\", 'NN'), ('here', 'RB'), (',', ','), ('content', 'NN'), ('here', 'RB'), (\"'\", \"''\"), (',', ','), ('making', 'VBG'), ('it', 'PRP'), ('look', 'VB'), ('like', 'IN'), ('readable', 'JJ'), ('English', 'NNP'), ('.', '.'), ('Many', 'JJ'), ('desktop', 'NN'), ('publishing', 'NN'), ('package', 'NN'), ('and', 'CC'), ('web', 'JJ'), ('page', 'NN'), ('editor', 'NN'), ('now', 'RB'), ('use', 'VBP'), ('Lorem', 'NNP'), ('Ipsum', 'NNP'), ('a', 'DT'), ('their', 'PRP$'), ('default', 'NN'), ('model', 'NN'), ('text', 'NN'), (',', ','), ('and', 'CC'), ('a', 'DT'), ('search', 'NN'), ('for', 'IN'), (\"'lorem\", 'NNP'), ('ipsum', 'NN'), (\"'\", \"''\"), ('will', 'MD'), ('uncover', 'VB'), ('many', 'JJ'), ('web', 'NNS'), ('site', 'NN'), ('still', 'RB'), ('in', 'IN'), ('their', 'PRP$'), ('infancy', 'NN'), ('.', '.'), ('Various', 'JJ'), ('version', 'NN'), ('have', 'VBP'), ('evolved', 'VBN'), ('over', 'IN'), ('the', 'DT'), ('year', 'NN'), (',', ','), ('sometimes', 'RB'), ('by', 'IN'), ('accident', 'NN'), (',', ','), ('sometimes', 'RB'), ('on', 'IN'), ('purpose', 'NN'), ('(', '('), ('injected', 'VBN'), ('humour', 'NN'), ('and', 'CC'), ('the', 'DT'), ('like', 'JJ'), (')', ')'), ('.There', 'EX'), ('are', 'VBP'), ('many', 'JJ'), ('variation', 'NN'), ('of', 'IN'), ('passage', 'NN'), ('of', 'IN'), ('Lorem', 'NNP'), ('Ipsum', 'NNP'), ('available', 'JJ'), (',', ','), ('but', 'CC'), ('the', 'DT'), ('majority', 'NN'), ('have', 'VBP'), ('suffered', 'VBN'), ('alteration', 'NN'), ('in', 'IN'), ('some', 'DT'), ('form', 'NN'), (',', ','), ('by', 'IN'), ('injected', 'JJ'), ('humour', 'NN'), (',', ','), ('or', 'CC'), ('randomised', 'VBD'), ('word', 'NN'), ('which', 'WDT'), ('do', 'VBP'), (\"n't\", 'RB'), ('look', 'VB'), ('even', 'RB'), ('slightly', 'RB'), ('believable', 'JJ'), ('.', '.'), ('If', 'IN'), ('you', 'PRP'), ('are', 'VBP'), ('going', 'VBG'), ('to', 'TO'), ('use', 'VB'), ('a', 'DT'), ('passage', 'NN'), ('of', 'IN'), ('Lorem', 'NNP'), ('Ipsum', 'NNP'), (',', ','), ('you', 'PRP'), ('need', 'VBP'), ('to', 'TO'), ('be', 'VB'), ('sure', 'JJ'), ('there', 'EX'), ('is', 'VBZ'), (\"n't\", 'RB'), ('anything', 'NN'), ('embarrassing', 'JJ'), ('hidden', 'NN'), ('in', 'IN'), ('the', 'DT'), ('middle', 'NN'), ('of', 'IN'), ('text', 'NN'), ('.', '.'), ('All', 'PDT'), ('the', 'DT'), ('Lorem', 'NNP'), ('Ipsum', 'NNP'), ('generator', 'NN'), ('on', 'IN'), ('the', 'DT'), ('Internet', 'NNP'), ('tend', 'NN'), ('to', 'TO'), ('repeat', 'VB'), ('predefined', 'JJ'), ('chunk', 'NN'), ('a', 'DT'), ('necessary', 'JJ'), (',', ','), ('making', 'VBG'), ('this', 'DT'), ('the', 'DT'), ('first', 'JJ'), ('true', 'JJ'), ('generator', 'NN'), ('on', 'IN'), ('the', 'DT'), ('Internet', 'NNP'), ('.', '.'), ('It', 'PRP'), ('us', 'PRP'), ('a', 'DT'), ('dictionary', 'NN'), ('of', 'IN'), ('over', 'IN'), ('200', 'CD'), ('Latin', 'JJ'), ('word', 'NN'), (',', ','), ('combined', 'VBN'), ('with', 'IN'), ('a', 'DT'), ('handful', 'NN'), ('of', 'IN'), ('model', 'JJ'), ('sentence', 'NN'), ('structure', 'NN'), (',', ','), ('to', 'TO'), ('generate', 'VB'), ('Lorem', 'NNP'), ('Ipsum', 'NNP'), ('which', 'WDT'), ('look', 'VBP'), ('reasonable', 'JJ'), ('.', '.'), ('The', 'DT'), ('generated', 'JJ'), ('Lorem', 'NNP'), ('Ipsum', 'NNP'), ('is', 'VBZ'), ('therefore', 'RB'), ('always', 'RB'), ('free', 'JJ'), ('from', 'IN'), ('repetition', 'NN'), (',', ','), ('injected', 'VBD'), ('humour', 'NN'), (',', ','), ('or', 'CC'), ('non-characteristic', 'JJ'), ('word', 'NN'), ('etc', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "POS_tag = nltk.pos_tag(lemmatized_text)\n",
    "\n",
    "print(\"Lemmatized text with POS tags: \\n\")\n",
    "print(POS_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any word from the lemmatized text, which isn't a noun, adjective, or gerund (or a 'foreign word'), is here\n",
    "considered as a <b>stopword</b> (non-content). This is based on the assumption that usually keywords are noun,\n",
    "adjectives or gerunds. \n",
    "\n",
    "Punctuations are added to the stopword list too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = []\n",
    "\n",
    "wanted_POS = ['NN','NNS','NNP','NNPS','JJ','JJR','JJS','VBG','FW'] \n",
    "\n",
    "for word in POS_tag:\n",
    "    if word[1] not in wanted_POS:\n",
    "        stopwords.append(word[0])\n",
    "\n",
    "punctuations = list(str(string.punctuation))\n",
    "\n",
    "stopwords = stopwords + punctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if we remove the aforementioned stopwords, still some extremely common nouns, adjectives or gerunds may\n",
    "remain which are very bad candidates for being keywords (or part of it). \n",
    "\n",
    "An external file constituting a long list of stopwords is loaded and all the words are added with the previous\n",
    "stopwords to create the final list 'stopwords-plus' which is then converted into a set. \n",
    "\n",
    "(Source of stopwords data: https://www.ranks.nl/stopwords)\n",
    "\n",
    "Stopwords-plus constitute the sum total of all stopwords and potential phrase-delimiters. The contents of this\n",
    "set will be used to partition the lemmatized text into phrases. \n",
    "\n",
    "Phrases should constitute a group of consecutively occuring words that has no member from stopwords_plus in\n",
    "between. Example: \"Neural Network\".\n",
    "    \n",
    "Each phrase is a <b>keyword candidate</b>. \n",
    "    \n",
    "There are some exceptions, that is, there are some possible cases where a good keyword candidate may contain \n",
    "stopword in between. Example: \"Word of Mouth\". \n",
    "    \n",
    "But, for simplicity's sake I will pretend here that such exceptions do not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_file = open(\"F:/python progs/RAKE-tutorial-master/RAKE-tutorial-master/stopwords.txt\", \"r\")\n",
    "#Source = https://www.ranks.nl/stopwords\n",
    "\n",
    "lots_of_stopwords = []\n",
    "\n",
    "for line in stopword_file.readlines():\n",
    "    lots_of_stopwords.append(str(line.strip()))\n",
    "\n",
    "stopwords_plus = []\n",
    "stopwords_plus = stopwords + lots_of_stopwords\n",
    "stopwords_plus = set(stopwords_plus)\n",
    "\n",
    "#Stopwords_plus contain total set of all stopwords and phrase delimiters that\n",
    "#will be used for partitioning the text into phrases (candidate keywords)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phrases are generated by partitioning the lemmatized text using the members of stopwords_plus \n",
    "as delimiters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioned Phrases: \n",
      "\n",
      "[['Lorem', 'Ipsum'], ['dummy', 'text'], ['printing'], ['typesetting', 'industry'], ['Lorem', 'Ipsum'], ['industry'], ['standard', 'dummy', 'text'], ['unknown', 'printer'], ['galley'], ['type'], ['type', 'specimen', 'book'], ['century'], ['leap'], ['electronic', 'typesetting'], ['remaining'], ['unchanged'], ['1960s'], ['release'], ['Letraset', 'sheet'], ['Lorem', 'Ipsum', 'passage'], ['desktop', 'publishing', 'software'], ['Aldus', 'PageMaker', 'including', 'version'], ['Lorem', 'Ipsum'], ['long'], ['fact'], ['reader'], ['readable', 'content'], ['point'], ['Lorem', 'Ipsum'], ['more-or-less', 'normal', 'distribution'], ['letter'], [\"'Content\"], ['content'], ['making'], ['readable', 'English'], ['Many', 'desktop', 'publishing', 'package'], ['web'], ['editor'], ['Lorem', 'Ipsum'], ['default', 'model', 'text'], ['search'], [\"'lorem\", 'ipsum'], ['web', 'site'], ['infancy'], ['Various', 'version'], ['year'], ['accident'], ['purpose'], ['humour'], ['variation'], ['passage'], ['Lorem', 'Ipsum'], ['majority'], ['alteration'], ['form'], ['humour'], ['word'], ['believable'], ['going'], ['passage'], ['Lorem', 'Ipsum'], ['sure'], ['embarrassing', 'hidden'], ['middle'], ['text'], ['Lorem', 'Ipsum', 'generator'], ['Internet', 'tend'], ['predefined', 'chunk'], ['making'], ['true', 'generator'], ['Internet'], ['dictionary'], ['Latin', 'word'], ['handful'], ['model', 'sentence', 'structure'], ['Lorem', 'Ipsum'], ['reasonable'], ['generated', 'Lorem', 'Ipsum'], ['free'], ['repetition'], ['humour'], ['non-characteristic', 'word']]\n"
     ]
    }
   ],
   "source": [
    "phrases = []\n",
    "\n",
    "phrase = \" \"\n",
    "for word in lemmatized_text:\n",
    "    \n",
    "    if word in stopwords_plus:\n",
    "        if phrase!= \" \":\n",
    "            phrases.append(str(phrase).split())\n",
    "        phrase = \" \"\n",
    "    elif word not in stopwords_plus:\n",
    "        phrase+=str(word)\n",
    "        phrase+=\" \"\n",
    "\n",
    "print(\"Partitioned Phrases: \\n\")\n",
    "print(phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency of each words in the list of phrases, are calculated here. \n",
    "\n",
    "The degree of each words are calculating by adding the length of all the\n",
    "phrases where the word occurs.\n",
    "\n",
    "Each word scores are caclulated by dividing degree of the word by its frequency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary of degree scores for each words under candidate keywords (phrases): \n",
      "\n",
      "defaultdict(<class 'int'>, {'Lorem': 25, 'Ipsum': 25, 'dummy': 5, 'text': 9, 'printing': 1, 'typesetting': 4, 'industry': 3, 'standard': 3, 'unknown': 2, 'printer': 2, 'galley': 1, 'type': 4, 'specimen': 3, 'book': 3, 'century': 1, 'leap': 1, 'electronic': 2, 'remaining': 1, 'unchanged': 1, '1960s': 1, 'release': 1, 'Letraset': 2, 'sheet': 2, 'passage': 5, 'desktop': 7, 'publishing': 7, 'software': 3, 'Aldus': 4, 'PageMaker': 4, 'including': 4, 'version': 6, 'long': 1, 'fact': 1, 'reader': 1, 'readable': 4, 'content': 3, 'point': 1, 'more-or-less': 3, 'normal': 3, 'distribution': 3, 'letter': 1, \"'Content\": 1, 'making': 2, 'English': 2, 'Many': 4, 'package': 4, 'web': 3, 'editor': 1, 'default': 3, 'model': 6, 'search': 1, \"'lorem\": 2, 'ipsum': 2, 'site': 2, 'infancy': 1, 'Various': 2, 'year': 1, 'accident': 1, 'purpose': 1, 'humour': 3, 'variation': 1, 'majority': 1, 'alteration': 1, 'form': 1, 'word': 5, 'believable': 1, 'going': 1, 'sure': 1, 'embarrassing': 2, 'hidden': 2, 'middle': 1, 'generator': 5, 'Internet': 3, 'tend': 2, 'predefined': 2, 'chunk': 2, 'true': 2, 'dictionary': 1, 'Latin': 2, 'handful': 1, 'sentence': 3, 'structure': 3, 'reasonable': 1, 'generated': 3, 'free': 1, 'repetition': 1, 'non-characteristic': 2})\n",
      "\n",
      "Dictionary of frequencies for each words under candidate keywords (phrases): \n",
      "\n",
      "defaultdict(<class 'int'>, {'Lorem': 11, 'Ipsum': 11, 'dummy': 2, 'text': 4, 'printing': 1, 'typesetting': 2, 'industry': 2, 'standard': 1, 'unknown': 1, 'printer': 1, 'galley': 1, 'type': 2, 'specimen': 1, 'book': 1, 'century': 1, 'leap': 1, 'electronic': 1, 'remaining': 1, 'unchanged': 1, '1960s': 1, 'release': 1, 'Letraset': 1, 'sheet': 1, 'passage': 3, 'desktop': 2, 'publishing': 2, 'software': 1, 'Aldus': 1, 'PageMaker': 1, 'including': 1, 'version': 2, 'long': 1, 'fact': 1, 'reader': 1, 'readable': 2, 'content': 2, 'point': 1, 'more-or-less': 1, 'normal': 1, 'distribution': 1, 'letter': 1, \"'Content\": 1, 'making': 2, 'English': 1, 'Many': 1, 'package': 1, 'web': 2, 'editor': 1, 'default': 1, 'model': 2, 'search': 1, \"'lorem\": 1, 'ipsum': 1, 'site': 1, 'infancy': 1, 'Various': 1, 'year': 1, 'accident': 1, 'purpose': 1, 'humour': 3, 'variation': 1, 'majority': 1, 'alteration': 1, 'form': 1, 'word': 3, 'believable': 1, 'going': 1, 'sure': 1, 'embarrassing': 1, 'hidden': 1, 'middle': 1, 'generator': 2, 'Internet': 2, 'tend': 1, 'predefined': 1, 'chunk': 1, 'true': 1, 'dictionary': 1, 'Latin': 1, 'handful': 1, 'sentence': 1, 'structure': 1, 'reasonable': 1, 'generated': 1, 'free': 1, 'repetition': 1, 'non-characteristic': 1})\n",
      "\n",
      "Dictionary of word scores for each words under candidate keywords (phrases): \n",
      "\n",
      "defaultdict(<class 'float'>, {'Lorem': 2.272727272727273, 'Ipsum': 2.272727272727273, 'dummy': 2.5, 'text': 2.25, 'printing': 1.0, 'typesetting': 2.0, 'industry': 1.5, 'standard': 3.0, 'unknown': 2.0, 'printer': 2.0, 'galley': 1.0, 'type': 2.0, 'specimen': 3.0, 'book': 3.0, 'century': 1.0, 'leap': 1.0, 'electronic': 2.0, 'remaining': 1.0, 'unchanged': 1.0, '1960s': 1.0, 'release': 1.0, 'Letraset': 2.0, 'sheet': 2.0, 'passage': 1.6666666666666667, 'desktop': 3.5, 'publishing': 3.5, 'software': 3.0, 'Aldus': 4.0, 'PageMaker': 4.0, 'including': 4.0, 'version': 3.0, 'long': 1.0, 'fact': 1.0, 'reader': 1.0, 'readable': 2.0, 'content': 1.5, 'point': 1.0, 'more-or-less': 3.0, 'normal': 3.0, 'distribution': 3.0, 'letter': 1.0, \"'Content\": 1.0, 'making': 1.0, 'English': 2.0, 'Many': 4.0, 'package': 4.0, 'web': 1.5, 'editor': 1.0, 'default': 3.0, 'model': 3.0, 'search': 1.0, \"'lorem\": 2.0, 'ipsum': 2.0, 'site': 2.0, 'infancy': 1.0, 'Various': 2.0, 'year': 1.0, 'accident': 1.0, 'purpose': 1.0, 'humour': 1.0, 'variation': 1.0, 'majority': 1.0, 'alteration': 1.0, 'form': 1.0, 'word': 1.6666666666666667, 'believable': 1.0, 'going': 1.0, 'sure': 1.0, 'embarrassing': 2.0, 'hidden': 2.0, 'middle': 1.0, 'generator': 2.5, 'Internet': 1.5, 'tend': 2.0, 'predefined': 2.0, 'chunk': 2.0, 'true': 2.0, 'dictionary': 1.0, 'Latin': 2.0, 'handful': 1.0, 'sentence': 3.0, 'structure': 3.0, 'reasonable': 1.0, 'generated': 3.0, 'free': 1.0, 'repetition': 1.0, 'non-characteristic': 2.0})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "frequency = defaultdict(int)\n",
    "degree = defaultdict(int)\n",
    "word_score = defaultdict(float)\n",
    "\n",
    "vocabulary = []\n",
    "\n",
    "for phrase in phrases:\n",
    "    for word in phrase:\n",
    "        frequency[word]+=1\n",
    "        degree[word]+=len(phrase)\n",
    "        if word not in vocabulary:\n",
    "            vocabulary.append(word)\n",
    "            \n",
    "for word in vocabulary:\n",
    "    word_score[word] = degree[word]/frequency[word]\n",
    "\n",
    "print(\"Dictionary of degree scores for each words under candidate keywords (phrases): \\n\")\n",
    "print(degree)\n",
    "print(\"\\nDictionary of frequencies for each words under candidate keywords (phrases): \\n\")\n",
    "print(frequency)\n",
    "print(\"\\nDictionary of word scores for each words under candidate keywords (phrases): \\n\")\n",
    "print(word_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The phrase scores are calculated by adding individual scores of each of the words\n",
    "which form the members of the phrase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of candidate keyword 'Lorem Ipsum': 4.545454545454546\n",
      "Score of candidate keyword 'dummy text': 4.75\n",
      "Score of candidate keyword 'printing': 1.0\n",
      "Score of candidate keyword 'typesetting industry': 3.5\n",
      "Score of candidate keyword 'industry': 1.5\n",
      "Score of candidate keyword 'standard dummy text': 7.75\n",
      "Score of candidate keyword 'unknown printer': 4.0\n",
      "Score of candidate keyword 'galley': 1.0\n",
      "Score of candidate keyword 'type': 2.0\n",
      "Score of candidate keyword 'type specimen book': 8.0\n",
      "Score of candidate keyword 'century': 1.0\n",
      "Score of candidate keyword 'leap': 1.0\n",
      "Score of candidate keyword 'electronic typesetting': 4.0\n",
      "Score of candidate keyword 'remaining': 1.0\n",
      "Score of candidate keyword 'unchanged': 1.0\n",
      "Score of candidate keyword '1960s': 1.0\n",
      "Score of candidate keyword 'release': 1.0\n",
      "Score of candidate keyword 'Letraset sheet': 4.0\n",
      "Score of candidate keyword 'Lorem Ipsum passage': 6.212121212121213\n",
      "Score of candidate keyword 'desktop publishing software': 10.0\n",
      "Score of candidate keyword 'Aldus PageMaker including version': 15.0\n",
      "Score of candidate keyword 'long': 1.0\n",
      "Score of candidate keyword 'fact': 1.0\n",
      "Score of candidate keyword 'reader': 1.0\n",
      "Score of candidate keyword 'readable content': 3.5\n",
      "Score of candidate keyword 'point': 1.0\n",
      "Score of candidate keyword 'more-or-less normal distribution': 9.0\n",
      "Score of candidate keyword 'letter': 1.0\n",
      "Score of candidate keyword ''Content': 1.0\n",
      "Score of candidate keyword 'content': 1.5\n",
      "Score of candidate keyword 'making': 1.0\n",
      "Score of candidate keyword 'readable English': 4.0\n",
      "Score of candidate keyword 'Many desktop publishing package': 15.0\n",
      "Score of candidate keyword 'web': 1.5\n",
      "Score of candidate keyword 'editor': 1.0\n",
      "Score of candidate keyword 'default model text': 8.25\n",
      "Score of candidate keyword 'search': 1.0\n",
      "Score of candidate keyword ''lorem ipsum': 4.0\n",
      "Score of candidate keyword 'web site': 3.5\n",
      "Score of candidate keyword 'infancy': 1.0\n",
      "Score of candidate keyword 'Various version': 5.0\n",
      "Score of candidate keyword 'year': 1.0\n",
      "Score of candidate keyword 'accident': 1.0\n",
      "Score of candidate keyword 'purpose': 1.0\n",
      "Score of candidate keyword 'humour': 1.0\n",
      "Score of candidate keyword 'variation': 1.0\n",
      "Score of candidate keyword 'passage': 1.6666666666666667\n",
      "Score of candidate keyword 'majority': 1.0\n",
      "Score of candidate keyword 'alteration': 1.0\n",
      "Score of candidate keyword 'form': 1.0\n",
      "Score of candidate keyword 'word': 1.6666666666666667\n",
      "Score of candidate keyword 'believable': 1.0\n",
      "Score of candidate keyword 'going': 1.0\n",
      "Score of candidate keyword 'sure': 1.0\n",
      "Score of candidate keyword 'embarrassing hidden': 4.0\n",
      "Score of candidate keyword 'middle': 1.0\n",
      "Score of candidate keyword 'text': 2.25\n",
      "Score of candidate keyword 'Lorem Ipsum generator': 7.045454545454546\n",
      "Score of candidate keyword 'Internet tend': 3.5\n",
      "Score of candidate keyword 'predefined chunk': 4.0\n",
      "Score of candidate keyword 'true generator': 4.5\n",
      "Score of candidate keyword 'Internet': 1.5\n",
      "Score of candidate keyword 'dictionary': 1.0\n",
      "Score of candidate keyword 'Latin word': 3.666666666666667\n",
      "Score of candidate keyword 'handful': 1.0\n",
      "Score of candidate keyword 'model sentence structure': 9.0\n",
      "Score of candidate keyword 'reasonable': 1.0\n",
      "Score of candidate keyword 'generated Lorem Ipsum': 7.545454545454547\n",
      "Score of candidate keyword 'free': 1.0\n",
      "Score of candidate keyword 'repetition': 1.0\n",
      "Score of candidate keyword 'non-characteristic word': 3.666666666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "phrase_scores = []\n",
    "keywords = []\n",
    "phrase_vocabulary=[]\n",
    "\n",
    "for phrase in phrases:\n",
    "    if phrase not in phrase_vocabulary:\n",
    "        phrase_score=0\n",
    "        for word in phrase:\n",
    "            phrase_score+= word_score[word]\n",
    "        phrase_scores.append(phrase_score)\n",
    "        phrase_vocabulary.append(phrase)\n",
    "\n",
    "phrase_vocabulary = []\n",
    "j=0\n",
    "for phrase in phrases:\n",
    "    \n",
    "    if phrase not in phrase_vocabulary:\n",
    "        keyword=''\n",
    "        for word in phrase:\n",
    "            keyword += str(word)+\" \"\n",
    "        phrase_vocabulary.append(phrase)\n",
    "        keyword = keyword.strip()\n",
    "        keywords.append(keyword)\n",
    "    \n",
    "        print (\"Score of candidate keyword '\"+keywords[j]+\"': \"+str(phrase_scores[j]))\n",
    "        \n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index of the phrase score ndarray is then sorted in descending order in terms of\n",
    "the score values.\n",
    "The index corresponds to the location of the concerned phrase in phrases list.\n",
    "So by getting the sorted order of the index, we also get the sorted order of the phrases.\n",
    "Each phrase can be considered as a <b>candidate keyword</b>. \n",
    "We can then simply choose the top n highest scoring candidate keywords and present them as\n",
    "the final exctracted keywords for the system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords:\n",
      "\n",
      "Aldus PageMaker including version, \n",
      "Many desktop publishing package, \n",
      "desktop publishing software, \n",
      "model sentence structure, \n",
      "more-or-less normal distribution, \n",
      "default model text, \n",
      "type specimen book, \n",
      "standard dummy text, \n",
      "generated Lorem Ipsum, \n",
      "Lorem Ipsum generator, \n"
     ]
    }
   ],
   "source": [
    "sorted_index = np.flip(np.argsort(phrase_scores),0)\n",
    "\n",
    "keywords_num = 10\n",
    "\n",
    "print(\"Keywords:\\n\")\n",
    "\n",
    "for i in range(0,keywords_num):\n",
    "    print(str(keywords[sorted_index[i]])+\", \",)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
